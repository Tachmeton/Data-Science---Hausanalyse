{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ersteller: Till Fetzer (Wahlfach), Bastian Frewert (1641654, Wahlfach)\n",
    "Dozent/-in: Prof. Dr. Monika Kochanowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "#Allgemein\n",
    "import pandas as pd\n",
    "import seaborn  as sb\n",
    "\n",
    "# Bewertungsmetriken\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, confusion_matrix\n",
    "\n",
    "#Text to numbers\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Models speichern und laden\n",
    "from joblib import dump, load\n",
    "\n",
    "#Außerdem genutzt: graphviz 2.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methoden zum Anwenden von Modellen und Bewerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doEverythingRegression(filename):\n",
    "    regressionModel, classificationModel = importModels(\"trainedModels.joblib\")\n",
    "    classificationData = readData(filename)\n",
    "    return applyRegressor(regressionModel, classificationData)\n",
    "\n",
    "def doEverythingClassification(filename):\n",
    "    regressionModel, classificationModel = importModels(\"trainedModels.joblib\")\n",
    "    regressionData = readData(filename)\n",
    "    return applyClassifier(classificationModel, regressionData)\n",
    "    \n",
    "\n",
    "def readData(filename):\n",
    "    if str(filename):\n",
    "        dataFrame = pd.read_csv(filename, sep= \";\")\n",
    "        return dataFrame;\n",
    "    \n",
    "def prepareDataRegression(dataFrame):\n",
    "    if type(dataFrame) == pd.core.frame.DataFrame:\n",
    "        #Data Preparation\n",
    "        #Spalten entfernen\n",
    "        if \"YrSold\" in dataFrame.columns:\n",
    "            dataFrame = dataFrame.drop(\"YrSold\", axis=1)\n",
    "        #Dies wird entfernt wei lman oben herruasgefunden hat das es mit nichts correliert\n",
    "        # es also keine auswirkung auf irgendwas hat. und es auch nur 4 verschiedene Werte sind. \n",
    "        if \"TotRmsAbvGrd\" in dataFrame.columns:\n",
    "            dataFrame = dataFrame.drop(\"TotRmsAbvGrd\", axis=1)\n",
    "        #Dies wird entfernt,\n",
    "        #weil es eine sehr starke mit LIvArea zu sammenhängt man also die gleiche Information in zwei Features hat.\n",
    "        \n",
    "        \n",
    "        #One hot encoding\n",
    "        stringLabels = [\"MSZoning\",\"Neighborhood\",\"BldgType\",\"RoofStyle\",\"HeatingQC\",\"CentralAir\"]\n",
    "        for element in stringLabels:\n",
    "            dataFrame.loc[:,element] = text_to_numbers(dataFrame.loc[:,element])\n",
    "            \n",
    "        return dataFrame\n",
    "    \n",
    "def splitDataRegression(dataFrame):\n",
    "    if type(dataFrame) == pd.core.frame.DataFrame:\n",
    "        #Data Splitting in Data und Sale Price\n",
    "        x = dataFrame.drop('SalePrice', axis=1)\n",
    "        y = dataFrame.SalePrice\n",
    "        return x,y\n",
    "            \n",
    "def applyRegressor(model, dataFrame):\n",
    "    if type(dataFrame) == pd.core.frame.DataFrame:\n",
    "        dataFrame = prepareDataRegression(dataFrame)\n",
    "        x,y = splitDataRegression(dataFrame)\n",
    "        \n",
    "        if isinstance(model, sklearn.linear_model.base.LinearRegression) :\n",
    "            #nutzen von nur 3 Features bei der Linearen Regression.\n",
    "            #hier eventuell bei Fehler _base oder base schreiben!!!!!\n",
    "            x = x.iloc[:, [4 ,9, 12]]\n",
    "\n",
    "\n",
    "        #Führe Prediction durch und berechne Messwerte\n",
    "        pred = model.predict(x)\n",
    "        r2 = r2_score(y,pred)\n",
    "        mse = mean_squared_error(y, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = np.mean(np.abs((y - pred) / y)) * 100\n",
    "        maxDiff = np.amax(np.subtract(y,pred))\n",
    "        \n",
    "        return {\"r2\":r2,\"mse\": mse,\"rmse\":rmse,\"mape\":mape,\"maxDiff\": maxDiff}\n",
    "        \n",
    "def splitDataClassification(dataFrame):\n",
    "    if type(dataFrame) == pd.core.frame.DataFrame:\n",
    "        x = dataFrame.drop(\"CentralAir\",axis = 1)\n",
    "        y = dataFrame[\"CentralAir\"]\n",
    "        return x,y\n",
    "\n",
    "def applyClassifier(model, dataFrame):\n",
    "    if type(dataFrame) == pd.core.frame.DataFrame:\n",
    "        dataFrame = prepareDataRegression(dataFrame)\n",
    "        x, y = splitDataClassification(dataFrame)\n",
    "        #Führe Prediction durch und berechne Messwerte\n",
    "        prediction = model.predict(x)\n",
    "        dataFrameSize = len(x.index)\n",
    "        confMat = confusion_matrix(y,prediction).flatten()\n",
    "        truePositive,falseNegative,falsePositive,trueNegative = np.array(confMat,dtype='f')\n",
    "\n",
    "        \n",
    "        if (trueNegative + falsePositive) > 0:\n",
    "            falsePositiveRate = falsePositive/(trueNegative + falsePositive)\n",
    "        else:\n",
    "            falsePositiveRate = 0\n",
    "        if (truePositive + falseNegative) > 0:\n",
    "            falseNegativeRate = falseNegative/(truePositive + falseNegative)\n",
    "        else:\n",
    "            falseNegativeRate = 0\n",
    "    \n",
    "        accuracy = (trueNegative + truePositive) / len(dataFrame)\n",
    "        \n",
    "        return {\"accuracy\": accuracy, \"falsePositiveRate\": falsePositiveRate, \"falseNegativeRate\": falseNegativeRate}\n",
    "\n",
    "\n",
    "def text_to_numbers(text, cutoff_for_rare_words = 1):\n",
    "    \"\"\"Function to convert text to numbers. Text must be tokenzied so that\n",
    "    test is presented as a list of words. The index number for a word\n",
    "    is based on its frequency (words occuring more often have a lower index).\n",
    "    If a word does not occur as many times as cutoff_for_rare_words,\n",
    "    then it is given a word index of zero. All rare words will be zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten list if sublists are present\n",
    "    if len(text) > 1:\n",
    "        flat_text = [sublist for sublist in text]\n",
    "        \n",
    "    else:\n",
    "        flat_text = text\n",
    "    \n",
    "    # get word freuqncy\n",
    "    fdist = nltk.FreqDist(flat_text)\n",
    "\n",
    "    # Convert to Pandas dataframe\n",
    "    df_fdist = pd.DataFrame.from_dict(fdist, orient='index')\n",
    "    df_fdist.columns = ['Frequency']\n",
    "\n",
    "    # Sort by word frequency\n",
    "    df_fdist.sort_values(by=['Frequency'], ascending=False, inplace=True)\n",
    "\n",
    "    # Add word index\n",
    "    number_of_words = df_fdist.shape[0]\n",
    "    df_fdist['word_index'] = list(np.arange(number_of_words)+1)\n",
    "\n",
    "   \n",
    "    \n",
    "    # Convert pandas to dictionary\n",
    "    word_dict = df_fdist['word_index'].to_dict()\n",
    "   \n",
    "    \n",
    "    # Use dictionary to convert words in text to numbers\n",
    "    text_numbers = []\n",
    "    for string in text:\n",
    "        string_numbers = word_dict[string]\n",
    "        text_numbers.append(string_numbers)  \n",
    "    \n",
    "    return (text_numbers)\n",
    "        \n",
    "        \n",
    "def exportModels(filename, regressionModel, classificationModel):\n",
    "    dump([regressionModel, classificationModel], filename)\n",
    "    \n",
    "def importModels(filename):\n",
    "    return load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_to_numbers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4491d5fdf979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoEverythingRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SetFiltered.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-27d628aaca32>\u001b[0m in \u001b[0;36mdoEverythingRegression\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mregressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassificationModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trainedModels.joblib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclassificationData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mapplyRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassificationData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdoEverythingClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-27d628aaca32>\u001b[0m in \u001b[0;36mapplyRegressor\u001b[1;34m(model, dataFrame)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapplyRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mdataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepareDataRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitDataRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-27d628aaca32>\u001b[0m in \u001b[0;36mprepareDataRegression\u001b[1;34m(dataFrame)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mstringLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"MSZoning\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Neighborhood\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"BldgType\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RoofStyle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"HeatingQC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CentralAir\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstringLabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mdataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_to_numbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_to_numbers' is not defined"
     ]
    }
   ],
   "source": [
    "doEverythingRegression(\"SetFiltered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doEverythingClassification(\"SetFiltered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Erkenntnisse first look\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SetFiltered.csv\", sep= \";\") \n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null gibt es sonst nicht\n",
    "NAN auch nicht\n",
    "-1 auch nicht "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[81:82]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Zeilen ist weil wenn man die csv mit Libre Office öffnet war (all) in einer anderen Spalte wodurch das ganze Datenset verschoben war.\n",
    "Dies ist nur um sicher zustellen, dass es nicht mehr so ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot Area riesiges Maximum kann riesige Auswirkungen haben. </br>\n",
    "Riesiges Minimum und Maximum </br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"LotArea\"].idxmax():data[\"LotArea\"].idxmax()+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MSZoning\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C (all) ist nur alleine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query(\"MSZoning != 'C (all)'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es nur ein C(all) gibt steckt in C(all) keine Information und es wird gesaubert in Sinne der Daten aufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blueste kommt nur einmal vor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query(\"Neighborhood != 'Blueste'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Grund warum dies gemacht wird ist,  man kann mit der Information Blueste ncihts anfangen wenn es nur einen Eintrag gibt nichts anfangen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BldgType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einfamiliehaushalt ist am häufigsten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OverallQual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['OverallQual'].value_counts().keys(), data['OverallQual'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "schaut nach einer Gaussverteilung aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OverallCond'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['OverallCond'].value_counts().keys(), data['OverallCond'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RoofStyle'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giebel und hip dach sind auf häufigsten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HeatingQC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "schlechte warmequaltität der Heizung ist nur ein Haus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CentralAir'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meiste haben eine Klimaanlage. 0,93% wichtig um Klassifiakation später zu beurteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['GrLivArea'].value_counts().keys(), data['GrLivArea'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viele kleine und der eine ausreisser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.lineplot(data['TotRmsAbvGrd'].value_counts().keys(), data['TotRmsAbvGrd'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieht gut aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['GarageCars'].value_counts().keys(), data['GarageCars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geht "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['YrSold'].value_counts().keys(), data['YrSold'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was war 2009.5 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['YrSold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Datensatz ist in nur 4 Jahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['YearBuilt'].value_counts().keys(), data['YearBuilt'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YearBuilt = data['YearBuilt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['YearRemodAdd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lineplot(data['YearRemodAdd'].value_counts().keys(), data['YearRemodAdd'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1950 gab es eine große renoirierungswelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starke corr zwischen preis mit Qulität, TotalMsmtSF, LivArea, größe Garage. außerdem livArea und room above ground, Idee: eines weglassen  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP = data.drop(columns = [\"TotRmsAbvGrd\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP = dataP.drop(columns = [\"YrSold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hat corr kaum relation mit SalePrice und auch mit den anderen keine, dassheißt hier gibt es keinen Mehrwert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil Daten doppelt mit livArea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb.scatterplot(dataP[\"GrLivArea\"],dataP[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadurch passen Ausreißer von Größe und Preis zusammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(dataP[\"OverallQual\"],dataP[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qualitat hat range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(dataP[\"LotArea\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viele Ausreißer nach oben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP = dataP.sample(frac=1, random_state = 42)\n",
    "#Die Daten zufällig anordnen, random state damit Beispielrechnung richtig und Ergebnisse gleich bleiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = dataP[\"SalePrice\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(dataP[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenDataSet = len(dataP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP.loc[:,\"MSZoning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringLabels = [\"MSZoning\",\"Neighborhood\",\"BldgType\",\"RoofStyle\",\"HeatingQC\",\"CentralAir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for element in stringLabels:\n",
    "    dataP.loc[:,element] = text_to_numbers(dataP.loc[:,element])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = dataP.loc[:,\"MSZoning\":\"GarageCars\"]\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = rawdata[0:math.floor(lenDataSet*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateData = rawdata[math.ceil(lenDataSet*0.8):math.floor(lenDataSet*0.95)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = rawdata[math.ceil(lenDataSet*0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = labels[0:math.floor(lenDataSet*0.8)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateLabels = labels[math.ceil(lenDataSet*0.8):math.floor(lenDataSet*0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels = labels[math.ceil(lenDataSet*0.95):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist bewusst das es auch vorgefertigte Methoden zum splitten gibt. Es wurde sich für diese Methode enschieden, weil diese für uns einfacher zu lesen war"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabenteil 2 - Vorhersage SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfR = RandomForestRegressor(n_estimators = 1000, random_state = 42, max_features = 3)\n",
    "rfR.fit(trainData, trainLabels)\n",
    "#n_estimators = Anzahl an trees \n",
    "#random_state = \n",
    "# max_featurs = anzahl der feautres maximal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR.score(validateData, validateLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfK = RandomForestRegressor(n_estimators = 1000, random_state = 42, max_features = 3)\n",
    "scores = cross_val_score(rfK, trainData, trainLabels, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfK = RandomForestRegressor(n_estimators = 1000, random_state = 42, max_features = \"sqrt\")\n",
    "scores = cross_val_score(rfK, trainData, trainLabels, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbR = GradientBoostingRegressor(\n",
    "    max_depth=1,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "gbR.fit(trainData, trainLabels)\n",
    "gbR.score(validateData, validateLabels)\n",
    "#gbr.predict(rawdata[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearData = trainData.iloc[:, [4 ,9, 12]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression().fit(linearData, trainLabels)\n",
    "#clf.coef_\n",
    "#clf.intercept_\n",
    "#clf.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearDataV = validateData.iloc[:, [4 ,9, 12]]\n",
    "clf.score(linearDataV,validateLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:4] #vvlt lieber dataP also data Prepared nehmen (weniger Spalten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SalePrice =  45.01412324 * OverallQual + 45.01412324 * TotalBsmtSF +  59.93549851 * GrLIvArea -93010.30612691233 \n",
    "SalePrice =  21778.7995944 * 8 + 45.01412324 * 1463 +   59.93549851 * 2622 - 93010.30612691233 (1)\n",
    "predicted SalePrice =  307941.8008510381\n",
    "actuelle SalePrice =  325000\n",
    "p(Abweichung) =  1 -307941.8008510381/325000 = 0.05248676661219054\n",
    "\n",
    "\n",
    "SalePrice =  21778.7995944 * 4 + 45.01412324 * 1440 +   59.93549851 * 1440 - 93010.30612691233 (2)\n",
    "predicted SalePrice =  148889.11174950577\n",
    "actuelle SalePrice =  118000\n",
    "p(Abweichung) =  118000/148889.11174950577 = 0.261772133470388\n",
    "\n",
    "SalePrice =  21778.7995944 * 5 + 45.01412324 * 1040 +   59.93549851 * 1040 - 93010.30612691233 (2)\n",
    "predicted SalePrice =  127672.29481644908\n",
    "actuelle SalePrice =  133000\n",
    "p(Abweichung) =  1 -127672.29481644908/133000 = 0.040057933710909155\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - 127672.29481644908/133000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(data.iloc[1:2, [4 ,9, 12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabenteil 3 - Vorhersage ob es eine Klimananlage gibt (Central Air)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurze Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caData = dataP.loc[:, dataP.columns != 'CentralAir']\n",
    "caData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caLabels = dataP[\"CentralAir\"]\n",
    "caLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaData = caData[0:math.floor(lenDataSet*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateCaData = caData[math.ceil(lenDataSet*0.8):math.floor(lenDataSet*0.95)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCaData = caData[math.ceil(lenDataSet*0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCaLabels = caLabels[0:math.floor(lenDataSet*0.8)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validateCaLabels = caLabels[math.ceil(lenDataSet*0.8):math.floor(lenDataSet*0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCaLabels = caLabels[math.ceil(lenDataSet*0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dtC= tree.DecisionTreeClassifier()\n",
    "dtC = dtC.fit(trainCaData, trainCaLabels)\n",
    "dtC.score(validateCaData,validateCaLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfC = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfC.fit(trainCaData, trainCaLabels)\n",
    "rfC.score(validateCaData, validateCaLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbC = GradientBoostingClassifier(n_estimators=20, max_features=2, max_depth=2, random_state=0)\n",
    "gbC.fit(trainCaData, trainCaLabels)\n",
    "gbC.score(validateCaData, validateCaLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93% der Häuser haben eine Klimaanlage. Beachten!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = []\n",
    "testdata = data[math.ceil(lenDataSet*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "rg.append(applyRegressor(clf,testdata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Tree Regression\n",
    "rg.append(applyRegressor(gbR,testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "rg.append(applyRegressor(rfR,testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=[]\n",
    "mse=[]\n",
    "rmse = []\n",
    "mape=[]\n",
    "maxD=[]\n",
    "for i in rg:\n",
    "    r2.append(i[\"r2\"])\n",
    "    mse.append(i[\"mse\"])\n",
    "    rmse.append(i[\"rmse\"])\n",
    "    mape.append(i[\"mape\"])\n",
    "    maxD.append(i[\"maxDiff\"])\n",
    "#r2\n",
    "sb.barplot([\"Linear\",\"Gradient Boosting Tree\",\"Random Forest\"],r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot([\"Linear\",\"Gradient Boosting Tree\",\"Random Forest\"],mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot([\"Linear\",\"Gradient Boosting Tree\",\"Random Forest\"],rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot([\"Linear\",\"Gradient Boosting Tree\",\"Random Forest\"],mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot([\"Linear\",\"Gradient Boosting Tree\",\"Random Forest\"],maxD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet ist der Lineare Regressor der mit Abstand schlechteste Regressor unserer Modelle, da es sich nur auf 3 Werte aus den gegebenen Werten bezieht und es vom Aufbau mit das leichteste ist.\n",
    "\n",
    "Gradient Boosting Tree Regressor und Random Forest Regressor unterscheiden sich in den Messwerten R^2, MSE und RMSE relativ wenig.\n",
    "Sie unterscheiden sich in der maximalen Differenz und dem MAPE Wert. Wir bevorzugen den MAPE Wert, weil die Maximale Differenz wenig aussagt, da sie durch einen Ausreißer stark verändert werden kann.\n",
    "Da aber Random Forest einen besseren MAPE Wert besitzt werden wir dieses Modell weiter optimieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "cl.append(applyClassifier(dtC, testdata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "cl.append(applyClassifier(rfC, testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Tree Classifier\n",
    "cl.append(applyClassifier(gbC, testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"accuracy\": accuracy, \"falsePositiveRate\": falsePositiveRate, \"falseNegativeRate\": falseNegativeRate}\n",
    "accuracy= []\n",
    "falsePositiveRate =[]\n",
    "falseNegativeRate = []\n",
    "\n",
    "for i in cl:\n",
    "    print(i)\n",
    "    accuracy.append(i[\"accuracy\"])\n",
    "    falsePositiveRate.append(i[\"falsePositiveRate\"])\n",
    "    falseNegativeRate.append(i[\"falseNegativeRate\"])\n",
    "    \n",
    "#r2\n",
    "sb.barplot([\"Tree\",\"Random Forest\",\"Gradient Boosting Tree\"],accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot([\"Tree\",\"Random Forest\",\"Gradient Boosting Tree\"],falsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.barplot([\"Tree\",\"Random Forest\",\"Gradient Boosting Tree\"],falseNegativeRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Entscheidungsbaum hat wie man sieht die höchste Accuracy und eine gegenüber den anderen Modellen kleinere false Positive Rate.\n",
    "\n",
    "Was auffällt: Bei allen Classifieren liegt die false Negative Rate bei 0.\n",
    "\n",
    "Aufgrund der höheren Accuracy und den allgemein besseren Werten entscheiden wir uns dafür den Entscheidungsbaum zu optimieren und später einzusetzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierung der Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alt:\n",
    "applyRegressor(rfR,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfR2 = RandomForestRegressor(n_estimators = 100000, random_state = 42, max_features = 3)\n",
    "#rfR2.fit(trainData, trainLabels)\n",
    "#applyRegressor(rfR2,testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine höhere Anzahl an Estimators bringt eine höhere Performance in den Messwerten, doch das Berechnen wird immer langsamer sodass wir den Wert für die Tests nicht weiter erhöhen werden als 10000.\n",
    "Die Performance der Messwerte scheint sich einem Grenzwert anzunähern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR3 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 3)\n",
    "rfR3.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR3,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR3 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 4)\n",
    "rfR3.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR3,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR4 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 10)\n",
    "rfR4.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR4,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR5 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 7)\n",
    "rfR5.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR5,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR6 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 6)\n",
    "rfR6.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR6,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfR7 = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 8)\n",
    "rfR7.fit(trainData, trainLabels)\n",
    "applyRegressor(rfR7,testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir entscheiden uns für einen Baum mit 6 Features, da er einen niedrigen MAPE Wert aufweißt und die anderen Faktoren, dadurch nicht so viel in Mitleidenschaft gezoigen werden, wie bei anderen Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfRFinal = RandomForestRegressor(n_estimators = 10000, random_state = 42, max_features = 6)\n",
    "rfRFinal.fit(trainData, trainLabels)\n",
    "applyRegressor(rfRFinal,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimieren des Decision Treee Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtC = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth = None, min_samples_split = 2)\n",
    "dtC = dtC.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtC, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtC2 = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = None, min_samples_split = 2)\n",
    "dtC2.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtC2, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtC3 = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 11, min_samples_split = 2)\n",
    "dtC3.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtC3, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtC4 = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth = 4, min_samples_split = 2)\n",
    "dtC4.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtC4, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobald man das Kriterium ändert und ein bisschen mit der Max Tiefe rumspielt, erhält man das Ergebnis, dass das Kriterium Gini anscheinend besser ist als Entropy, da es mit einer geringeren Tiefe von 4 (bei Gini) zu 11 (bie Entropy) die gelcihe Accuracy und Rates bringt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtC5 = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth = 4, min_samples_split = 26)\n",
    "dtC5.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtC5, testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variation von minimalen Samples bringt keine besseren Ergebnisse als wir nciht sowieso schon haben. Auch andere Variationen brachten keine weiteren Ergebnisse. Draraus folgend werden wir die Voreinstellungen mit Kriterium gleich Gini, einer unbegrenzten mmaximalen Tiefe und Splitten bei 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uns kommt das Ergebnis von einer Accuarcy von 0,96.... eher komisch vor aber wir finden keine Erklärung, deswegen arbeiten wir trotzdem damit weiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtCFinal = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth = None, min_samples_split = 2)\n",
    "dtCFinal.fit(trainCaData, trainCaLabels)\n",
    "applyClassifier(dtCFinal, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportModels(\"trainedModels.joblib\", rfRFinal, dtCFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwenden der Modelle auf Trainingsdatensatz, Testdatensatz, gesammten Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkung: Die Daten sind die gleichen wie oben verwendet da Reihenfolge immer gleich bleibt. Werden nur hier, wel sie vorher in Data und Labels getrennt wurden neu in Zeilen aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = data[0:math.floor(lenDataSet*0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data wird nicht benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = data[math.ceil(lenDataSet*0.95):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyRegressor(rfRFinal, trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyRegressor(rfRFinal, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyRegressor(rfRFinal, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyClassifier(dtCFinal, trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applyClassifier(dtCFinal, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyClassifier(dtCFinal, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals.six import StringIO  \n",
    "#from IPython.display import Image  \n",
    "#from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "#dot_data = StringIO()\n",
    "#feature_names = caData.columns\n",
    "#tree.export_graphviz(dtC, out_file=dot_data,\n",
    "#                     feature_names=feature_names ,\n",
    "#                     class_names=True)\n",
    "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(300,300))\n",
    "abc = tree.plot_tree(dtCFinal,feature_names = trainCaData.columns, filled = True, node_ids = False, fontsize = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
